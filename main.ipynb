{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee636fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"combined_dataset.json\", lines=True)\n",
    "df.to_csv(\"Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8faa31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376649ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2752 entries, 0 to 3511\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Context   2752 non-null   object\n",
      " 1   Response  2752 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 64.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def ProcessAndCombineText(text1,text2):\n",
    "    # Remove leading and trailing whitespace\n",
    "    text1 = text1.strip()\n",
    "    text2 = text2.strip()\n",
    "\n",
    "    # Replace newline characters with spaces\n",
    "    text1 = text1.replace(\"\\n\", \" \")\n",
    "    text2 = text2.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    text1 = re.sub(r'\\s+', ' ', text1)\n",
    "    text2 = re.sub(r'\\s+', ' ', text2)\n",
    "\n",
    "    # Add space after punctuation if not present\n",
    "    text1 = re.sub(r'([\\.\\,\\?\\!])(\\w)', r'\\1 \\2', text1)\n",
    "    text2 = re.sub(r'([\\.\\,\\?\\!])(\\w)', r'\\1 \\2', text2)\n",
    "\n",
    "    # Add label to the sentences for better understanding\n",
    "    text1 = \"Client: \" + text1\n",
    "    text2 = \"Assistant: \" + text2\n",
    "\n",
    "    # Combine the two texts\n",
    "    text = text1 + \"\\n\" + text2\n",
    "\n",
    "    return text\n",
    "\n",
    "df['combined'] = df.apply(lambda x: ProcessAndCombineText(x['Context'], x['Response']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83791bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone?\n",
      "Assistant: Hello, and thank you for your question and seeking advice on this. Feelings of worthlessness is unfortunately common. In fact, most people, if not all, have felt this to some degree at some point in their life. You are not alone. Changing our feelings is like changing our thoughts - it's hard to do. Our minds are so amazing that the minute you change your thought another one can be right there to take it's place. Without your permission, another thought can just pop in there. The new thought may feel worse than the last one! My guess is that you have tried several things to improve this on your own even before reaching out on here. People often try thinking positive thoughts, debating with their thoughts, or simply telling themselves that they need to \"snap out of it\" - which is also a thought that carries some self-criticism. Some people try a different approach, and there are counselors out there that can help you with this. The idea is that instead of trying to change the thoughts, you change how you respond to them. You learn skills that allow you to manage difficult thoughts and feelings differently so they don't have the same impact on you that they do right now. For some people, they actually DO begin to experience less hurtful thoughts once they learn how to manage the ones they have differently. Acceptance and Commitment Therapy may be a good choice for you. There is information online and even self-help books that you can use to teach you the skills that I mentioned. Because they are skills, they require practice, but many people have found great relief and an enriched life by learning them. As for suicidal thoughts, I am very glad to read that this has not happened to you. Still, you should watch out for this because it can be a sign of a worsening depression. If you begin to think about this, it is important to reach out to a support system right away. The National Suicide Prevention Lifeline is 1-800-273-8255. The text line is #741741. I hope some other colleagues will provide you more suggestions. Be well... Robin Landwehr, DBH, LPCC\n"
     ]
    }
   ],
   "source": [
    "print(df['combined'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcedfb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "df['embedding'] = df['combined'].apply(lambda x: get_embedding(x))\n",
    "\n",
    "# Save the embedding DF into a csv.\n",
    "df.to_csv('Dataset_with_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Function description\n",
    "# We can choose either to use the cosine_similarity(Inner Prodcut) or the similarity_score(Euclidean Distance)\n",
    "# Kayaknya lebih bagus kalo pake cosine_similarity - Domo \n",
    "\n",
    "def build_faiss_index(embeddings, mode):\n",
    "    # Convert to numpy array of float32\n",
    "    embedding_matrix = np.array(embeddings).astype(np.float32)\n",
    "    \n",
    "    # Get dimension\n",
    "    dimension = embedding_matrix.shape[1]\n",
    "\n",
    "    if mode == 'cosine':\n",
    "        faiss.normalize_L2(embedding_matrix)\n",
    "        index = faiss.IndexFlatIP(dimension)  # Inner Product â‰ˆ Cosine\n",
    "        index.add(embedding_matrix)\n",
    "\n",
    "    elif mode == 'similarity_score':\n",
    "        index = faiss.IndexFlatL2(dimension)  # Euclidean distance\n",
    "        index.add(embedding_matrix)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be either 'cosine' or 'similarity_score'\")\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Tokenize the combined text for BM25 (Optional: can try to use TF-IDF)\n",
    "documents = df['combined'].to_list()\n",
    "tokenized_documents = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "# Store the tokenized_documents in the BM25\n",
    "bm25 = BM25Okapi(tokenized_documents)\n",
    "\n",
    "# Function to get the BM25 score based on the query\n",
    "def GetBM25Score(query):\n",
    "    tokenized_query = word_tokenize(query.lower())\n",
    "    return bm25.get_scores(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a43a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSemanticScores(query, index, mode='cosine'):\n",
    "    # Embed the query\n",
    "    embedded_query = np.array([get_embedding(query)]).astype(np.float32)\n",
    "\n",
    "    if mode == 'cosine':\n",
    "        # Normalize query for cosine similarity\n",
    "        faiss.normalize_L2(embedded_query)\n",
    "        D, _ = index.search(embedded_query, k=index.ntotal)\n",
    "        return D[0]  # Cosine similarity (higher is better)\n",
    "\n",
    "    elif mode == 'similarity_score':\n",
    "        D, _ = index.search(embedded_query, k=index.ntotal)\n",
    "        return 1 / (D[0] + 1e-6)  # Convert L2 distance into similarity score\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'cosine' or 'similarity_score'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "def GetTopKDocumentsBasedOnQuery(query,index, mode,n, k):\n",
    "    bm25_scores = GetBM25Score(query)\n",
    "    semantic_scores = GetSemanticScores(query, index=index, mode=mode)\n",
    "\n",
    "    # Normalize each score becuase each have their own scale (Optional: can try to use Z-normalize)\n",
    "    bm25_scores_normalize = minmax_scale(bm25_scores)\n",
    "    semantic_scores_normalize = minmax_scale(semantic_scores)\n",
    "\n",
    "    # Set the weight of each score (Semantic, IMO Semantic is more important for mental health chatbot)\n",
    "    semantic_weight = 0.8\n",
    "    lexicon_weight = 0.2\n",
    "\n",
    "    # Combine each score\n",
    "    fused_scores = semantic_scores_normalize * semantic_weight + lexicon_weight * bm25_scores_normalize\n",
    "\n",
    "    # Get the top 20 scores\n",
    "    top_n = n\n",
    "    top_indices = np.argsort(fused_scores)[-top_n:][::-1]\n",
    "\n",
    "    # Get the top n documents that has the highest fused_scores\n",
    "    top_docs = [documents[i] for i in top_indices]\n",
    "\n",
    "    co = cohere.ClientV2(api_key=\"BELOM ADA\")\n",
    "\n",
    "    # Rerank the top n documents and take the top 2\n",
    "    response = co.rerank(\n",
    "        model = \"rerank-v3.5\",\n",
    "        query = query,\n",
    "        documents=top_docs,\n",
    "        top_n= k,\n",
    "    )\n",
    "\n",
    "    # Get the top ranked documents through the index from the output of the response.\n",
    "    return [top_docs[r.index] for r in response.results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89626dd9",
   "metadata": {},
   "source": [
    "## Should only be run once (might take some time), the code will:\n",
    "### 1. Select the mode of the FAISS DB index\n",
    "### 2. Turn the df['embedding'] into a list\n",
    "### 3. Build the FAISS DB with the appropriate index mode\n",
    "### 4. Insert the embedding documents into the FAISS DB\n",
    "### 5. Save the FAISS DB into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between cosine or similarity_score\n",
    "MODE = \"cosine\"\n",
    "\n",
    "# Turn the embedding data frame into list\n",
    "embeddings_documents = df['embedding'].to_list()\n",
    "\n",
    "index = build_faiss_index(embeddings=embeddings_documents,mode=MODE)\n",
    "\n",
    "# Save the index to a file so we can use it later\n",
    "faiss.write_index(index, \"sanity_llm_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58272adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the FAISS DB from a file, this is to prevent building the FAISS DB over and over\n",
    "index = faiss.read_index(\"sanity_llm_index.faiss\")\n",
    "\n",
    "query = \"Test\"\n",
    "\n",
    "# To indicate how many documents to be rank (Top n fused_scores will be rank)\n",
    "TopN = 20\n",
    "\n",
    "# To indicate how many documents to be returned after the reranking must be < TopN\n",
    "TopK = 10\n",
    "\n",
    "ranked_documents = GetTopKDocumentsBasedOnQuery(query=query,index=index,mode=MODE,n=TopN,k=TopK)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
